{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import datetime as dt\n",
    "import csv\n",
    "\n",
    "from scipy import sparse\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, LinearRegression, LogisticRegression, RidgeClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Loading dataset + defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_df = pd.read_csv('datasets\\\\science_dataset_updated2.csv') #Loads dataset\n",
    "sports_df = pd.read_csv('datasets\\\\sports_dataset_updated2.csv') #Loads dataset\n",
    "gaming_df = pd.read_csv('datasets\\\\gaming_dataset_updated2.csv') #Loads dataset\n",
    "wsb_df = pd.read_csv('datasets\\\\wsb_dataset_updated2.csv') #Loads dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original title:  Minecraft Map Banned In 20+ Countries\n",
      "Processed title:  ['minecraft', 'map', 'banned', 'countries']\n"
     ]
    }
   ],
   "source": [
    "print('Original title: ', gaming_df.title[1])\n",
    "print('Processed title: ', gaming_df.title_cleaned[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_ID</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>permalink</th>\n",
       "      <th>body</th>\n",
       "      <th>Flair</th>\n",
       "      <th>title length</th>\n",
       "      <th>24h_posttime</th>\n",
       "      <th>score</th>\n",
       "      <th>title_cleaned</th>\n",
       "      <th>score_class</th>\n",
       "      <th>has_body_text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>j2xstb</td>\n",
       "      <td>Framing COVID-19: How we conceptualize and dis...</td>\n",
       "      <td>https://doi.org/10.1371/journal.pone.0240010</td>\n",
       "      <td>scientist_1337</td>\n",
       "      <td>2020-10-01 02:03:19</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/science/comments/j2xstb/framing_covid19_how...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Social Science</td>\n",
       "      <td>199</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>[framing, covid, conceptualize, discuss, pande...</td>\n",
       "      <td>Last 80%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>j2xtrh</td>\n",
       "      <td>Framing COVID-19: How we conceptualize and dis...</td>\n",
       "      <td>https://journals.plos.org/plosone/article?id=1...</td>\n",
       "      <td>scientist_1337</td>\n",
       "      <td>2020-10-01 02:05:02</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/science/comments/j2xtrh/framing_covid19_how...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Social Science</td>\n",
       "      <td>199</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[framing, covid, conceptualize, discuss, pande...</td>\n",
       "      <td>Last 80%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>j2yv6u</td>\n",
       "      <td>whats science?</td>\n",
       "      <td>https://www.twitch.tv/tippothehippo</td>\n",
       "      <td>directorjames</td>\n",
       "      <td>2020-10-01 03:10:39</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/science/comments/j2yv6u/whats_science/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Social Science</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[whats, science]</td>\n",
       "      <td>Last 80%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>j2yzup</td>\n",
       "      <td>Providing decent living with minimum energy: A...</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "      <td>Helicase21</td>\n",
       "      <td>2020-10-01 03:19:04</td>\n",
       "      <td>7</td>\n",
       "      <td>/r/science/comments/j2yzup/providing_decent_li...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Environment</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>[providing, decent, living, minimum, energy, g...</td>\n",
       "      <td>Last 80%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j2zhbn</td>\n",
       "      <td>Neurotoxic effects associated with antibiotic use</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...</td>\n",
       "      <td>shripajeetmaharaj</td>\n",
       "      <td>2020-10-01 03:50:43</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/science/comments/j2zhbn/neurotoxic_effects_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Biology</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[neurotoxic, effects, associated, antibiotic, ...</td>\n",
       "      <td>Last 80%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_ID                                              title  \\\n",
       "0  j2xstb  Framing COVID-19: How we conceptualize and dis...   \n",
       "1  j2xtrh  Framing COVID-19: How we conceptualize and dis...   \n",
       "2  j2yv6u                                     whats science?   \n",
       "3  j2yzup  Providing decent living with minimum energy: A...   \n",
       "4  j2zhbn  Neurotoxic effects associated with antibiotic use   \n",
       "\n",
       "                                                 url             author  \\\n",
       "0       https://doi.org/10.1371/journal.pone.0240010     scientist_1337   \n",
       "1  https://journals.plos.org/plosone/article?id=1...     scientist_1337   \n",
       "2                https://www.twitch.tv/tippothehippo      directorjames   \n",
       "3  https://www.sciencedirect.com/science/article/...         Helicase21   \n",
       "4  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...  shripajeetmaharaj   \n",
       "\n",
       "             timestamp  comms_num  \\\n",
       "0  2020-10-01 02:03:19          0   \n",
       "1  2020-10-01 02:05:02          0   \n",
       "2  2020-10-01 03:10:39          2   \n",
       "3  2020-10-01 03:19:04          7   \n",
       "4  2020-10-01 03:50:43          1   \n",
       "\n",
       "                                           permalink body           Flair  \\\n",
       "0  /r/science/comments/j2xstb/framing_covid19_how...  NaN  Social Science   \n",
       "1  /r/science/comments/j2xtrh/framing_covid19_how...  NaN  Social Science   \n",
       "2          /r/science/comments/j2yv6u/whats_science/  NaN  Social Science   \n",
       "3  /r/science/comments/j2yzup/providing_decent_li...  NaN     Environment   \n",
       "4  /r/science/comments/j2zhbn/neurotoxic_effects_...  NaN         Biology   \n",
       "\n",
       "   title length  24h_posttime  score  \\\n",
       "0           199             2      9   \n",
       "1           199             2      1   \n",
       "2            14             3      1   \n",
       "3            62             3     17   \n",
       "4            49             3      2   \n",
       "\n",
       "                                       title_cleaned score_class  \\\n",
       "0  [framing, covid, conceptualize, discuss, pande...    Last 80%   \n",
       "1  [framing, covid, conceptualize, discuss, pande...    Last 80%   \n",
       "2                                   [whats, science]    Last 80%   \n",
       "3  [providing, decent, living, minimum, energy, g...    Last 80%   \n",
       "4  [neurotoxic, effects, associated, antibiotic, ...    Last 80%   \n",
       "\n",
       "   has_body_text   id  \n",
       "0            0.0  NaN  \n",
       "1            0.0  NaN  \n",
       "2            0.0  NaN  \n",
       "3            0.0  NaN  \n",
       "4            0.0  NaN  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df = pd.concat([science_df, sports_df, gaming_df, wsb_df], axis=0)\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_text_col(master_df, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) #Defines stopwords\n",
    "ps = PorterStemmer() #Defines stemmer\n",
    "\n",
    "def preprocess_text_col(dataframe, column_name): #Function for preprocessing text data for model-use by adding 'title-cleaned' column to given dataframe\n",
    "    def remove_punctuation(text): #Removes punctuation from string e.g. 'This is a string. This is another string' → 'this is a string This is another string' \n",
    "        no_punct=[words.lower() for words in text if words not in string.punctuation and words.isdigit() == False]\n",
    "        words_wo_punct=''.join(no_punct)\n",
    "        return words_wo_punct\n",
    "    def tokenize(text): #Tokenizes string e.g. 'This is a string' → ['this', 'is', 'a', 'string']\n",
    "        split=re.split(\"\\W+\", text)\n",
    "        return split\n",
    "    def remove_stopwords(text): #Removes stopwords list of strings e.g. ['this', 'is', 'a', 'string'] → ['string']\n",
    "        text=[word for word in text if word not in stop_words and word != '']\n",
    "        return text\n",
    "    def stem_nested_list(lst): #Stems words in a nested list and returns a nested list with stemmed words\n",
    "        master_list = []\n",
    "        for x in lst:\n",
    "            stemmed_list = [ps.stem(word) for word in x]\n",
    "            master_list.append(stemmed_list)\n",
    "        return master_list\n",
    "    \n",
    "    title_wo_punct = [remove_punctuation(x) for x in dataframe[column_name]]\n",
    "    title_wo_punct_split = [tokenize(word) for word in title_wo_punct]\n",
    "    title_wo_punct_split_stopwords = [remove_stopwords(word) for word in title_wo_punct_split]\n",
    "    dataframe['title_cleaned'] = title_wo_punct_split_stopwords\n",
    "#     dataframe['title_cleaned'] = stem_nested_list(title_wo_punct_split_stopwords)    \n",
    "\n",
    "def create_features(dataframe):\n",
    "    dataframe['timestamp'] = pd.to_datetime(dataframe['timestamp']) #Changing 'timestamp' column to dtype = datetime\n",
    "    dataframe['24h_posttime'] = dataframe['timestamp'].dt.hour #Adding hour posttime to dataset\n",
    "    \n",
    "    dataframe['score_class'] = \"\" #Creating the score_class column in the dataframe and filling it with empty strings\n",
    "    \n",
    "    dataframe['body'] = dataframe['body'].astype(str)\n",
    "    dataframe.loc[(dataframe['body'] == 'nan') | (dataframe['body'] == '[deleted]'), 'has_body_text'] = int(0) \n",
    "    dataframe.loc[(dataframe['body'] != 'nan') & (dataframe['body'] != '[deleted]'), 'has_body_text'] = int(1)\n",
    "#     dataframe['has_body_text'] = dataframe['has_body_text'].astype(int)\n",
    "    \n",
    "    for x in range(len(dataframe)): #Generates classes for score percentiles\n",
    "        if dataframe['score'][x] >= dataframe.score.quantile(0.99):\n",
    "            dataframe['score_class'][x] = 'Top 1%'\n",
    "        elif dataframe['score'][x] >= dataframe.score.quantile(0.95):\n",
    "            dataframe['score_class'][x] = 'Top 5%'\n",
    "        elif dataframe['score'][x] >= dataframe.score.quantile(0.9):\n",
    "            dataframe['score_class'][x] = 'Top 10%'\n",
    "        elif dataframe['score'][x] >= dataframe.score.quantile(0.8):\n",
    "            dataframe['score_class'][x] = 'Top 20%'\n",
    "        else:\n",
    "            dataframe['score_class'][x] = 'Last 80%'\n",
    "    \n",
    "def test_model(model): #Function for testing model(s)\n",
    "    if type(model) == list:\n",
    "        for x in range(len(model)):\n",
    "            print(\"Training score for {}: {:.3f}\".format(str(model[x]), model[x].score(X_train, y_train)))\n",
    "            print(\"Test score for {}: {:.2f}\\n\".format(str(model[x]), model[x].score(X_test, y_test)))\n",
    "    else:\n",
    "        print(\"Training score for {}: {:.3f}\".format(str(model), model.score(X_train, y_train)))\n",
    "        print(\"Test score for {}: {:.2f}\".format(str(model), model.score(X_test, y_test)))\n",
    "        \n",
    "def col_to_matrix(dataframe, column): #Function for converting a column from a pd.dataframe into a scipy.sparse.csr_matrix\n",
    "    matrix = dataframe[column].values[np.newaxis] #Creating 2D np array from column by adding an axis to original 1D array (df[col].values)\n",
    "    matrix = matrix.T #Transposing (rotating) array e.g. (1, 823) to (823, 1)\n",
    "    matrix = sparse.csr_matrix(matrix) #Creating matrix from array\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Preprocessing text-data for model-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent (hh:mm:ss): 0:00:00\n"
     ]
    }
   ],
   "source": [
    "begin_time = dt.datetime.now()\n",
    "\n",
    "def vectorize_dataframe(dataframe):\n",
    "    post_time = col_to_matrix(dataframe, '24h_posttime')\n",
    "    title_len = col_to_matrix(dataframe, 'title length')\n",
    "    has_body_text = col_to_matrix(dataframe, 'has_body_text')\n",
    "    preprocess_text_col(dataframe, 'title')\n",
    "\n",
    "    vectorizerbow = CountVectorizer(lowercase = False, analyzer=lambda x: x)\n",
    "    tfidfvectorizer = TfidfVectorizer(lowercase = False, analyzer=lambda x: x)\n",
    "\n",
    "    vectorizer = vectorizerbow\n",
    "    titles_vectorized_bow = vectorizer.fit_transform(dataframe['title_cleaned'])\n",
    "\n",
    "    titles_vectorized_bow = sparse.hstack((post_time, titles_vectorized_bow)) #Adding posttime column to matrix\n",
    "    titles_vectorized_bow = sparse.hstack((title_len, titles_vectorized_bow)) #Adding title_length column to matrix\n",
    "    titles_vectorized_bow = sparse.hstack((has_body_text, titles_vectorized_bow)) #Adding has_body_text column to matrix\n",
    "    return titles_vectorized_bow\n",
    "\n",
    "print('Time spent (hh:mm:ss):', dt.datetime.now() - begin_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Creating, training and testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gme 6073\n",
      "Max num use: 4.0\n"
     ]
    }
   ],
   "source": [
    "vectorize_dataframe(master_df)\n",
    "word = 'gme'\n",
    "print(word, 3+vectorizerbow.vocabulary_[word])\n",
    "print('Max num use:', titles_vectorized_bow_df[3+vectorizerbow.vocabulary_[word]].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 949.1679249836246\n",
      "1 729.2272727272727\n",
      "2 313.6666666666667\n",
      "3 652.0222222222222\n",
      "4 1487.1\n",
      "5 47.857142857142854\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "index = 6810\n",
    "wsb_0 = wsb_df.loc[titles_vectorized_bow_df[index] == 0]\n",
    "wsb_1 = wsb_df.loc[titles_vectorized_bow_df[index] == 1]\n",
    "wsb_2 = wsb_df.loc[titles_vectorized_bow_df[index] == 2]\n",
    "wsb_3 = wsb_df.loc[titles_vectorized_bow_df[index] == 3]\n",
    "wsb_4 = wsb_df.loc[titles_vectorized_bow_df[index] == 4]\n",
    "wsb_5 = wsb_df.loc[titles_vectorized_bow_df[index] == 5]\n",
    "\n",
    "print('0', wsb_0.score.mean())\n",
    "print('1', wsb_1.score.mean())\n",
    "print('2', wsb_2.score.mean())\n",
    "print('3', wsb_3.score.mean())\n",
    "print('4', wsb_4.score.mean())\n",
    "print('5', wsb_5.score.mean())\n",
    "print(len(wsb_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x=[0, 1, 2, 3, 4],  = [wsb_0.score.mean(), wsb_2.score.mean(), wsb_3.score.mean(), wsb_4.score.mean(), wsb_5.score.mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 31.4 GiB for an array with shape (86225, 48927) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-181-6a89612a7e25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvect_vocab_sorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorizerbow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Sorting dictionary of word:vector_index by vector_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtitles_vectorized_bow_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorize_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaster_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Creating DataFrame from vectorized titles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtitles_vectorized_bow_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitles_vectorized_bow_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Removing 'title_length', 'has_body_text' & '24h_posstime' columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvocab_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m         \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m         \u001b[0mfortran\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfortran\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 31.4 GiB for an array with shape (86225, 48927) and data type float64"
     ]
    }
   ],
   "source": [
    "vect_vocab_sorted = dict(sorted(vectorizer.vocabulary_.items(), key=lambda item: item[1])) # Sorting dictionary of word:vector_index by vector_index\n",
    "titles_vectorized_bow_df = pd.DataFrame(titles_vectorized_bow.toarray()) # Creating DataFrame from vectorized titles\n",
    "titles_vectorized_bow_df = titles_vectorized_bow_df.drop([0, 1, 2], axis=1) # Removing 'title_length', 'has_body_text' & '24h_posstime' columns\n",
    "\n",
    "vocab_dict = {}\n",
    "\n",
    "sum_vect = titles_vectorized_bow_df.sum(axis=0) #dataframe with sums of all vects across all rows\n",
    "\n",
    "for x in range(len(vect_vocab_sorted)): #Creating a dictionary consisting of word:sum pairs\n",
    "    vocab_dict[list(vect_vocab_sorted)[x]] = list(sum_vect)[x]\n",
    "\n",
    "sorted_vocab = dict(sorted(vocab_dict.items(), key=lambda item: item[1], reverse=True)) #Sorting the word:sum pairs by sum\n",
    "sorted_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge done  0:00:22.408795\n",
      "Neighbors: 1\n",
      "train score logged 0:03:26.738598\n",
      "test score logged 0:00:48.213553\n",
      "Neighbors: 2\n"
     ]
    }
   ],
   "source": [
    "begin_time = dt.datetime.now()\n",
    "\n",
    "target = master_df.score_class\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorize_dataframe(master_df), target, test_size = 0.2, random_state = 2021)\n",
    "\n",
    "results = {'Model':'Score'}\n",
    "for x in [0.01, 0.1, 1, 5, 10, 20]:\n",
    "    ridge = RidgeClassifier(alpha = x, max_iter=5000).fit(X_train, y_train)\n",
    "    results['ridge_training '+ str(x)] = ridge.score(X_train, y_train)\n",
    "    results['ridge_test '+ str(x)] = ridge.score(X_test, y_test)\n",
    "    \n",
    "ridge_time = dt.datetime.now()\n",
    "print('ridge done ', ridge_time - begin_time)\n",
    "\n",
    "# SVC_model = SVC().fit(X_train, y_train)\n",
    "# results['svc_training'] = SVC_model.score(X_train, y_train)\n",
    "# results['svc_test'] = SVC_model.score(X_test, y_test)\n",
    "\n",
    "svc_time = dt.datetime.now()\n",
    "# print('svc done ', svc_time - ridge_time)\n",
    "\n",
    "for x in range(1, 8):\n",
    "    print('Neighbors:', x)\n",
    "    start_time = dt.datetime.now()\n",
    "    knn = KNeighborsClassifier(n_neighbors = x, n_jobs=-1).fit(X_train, y_train)\n",
    "    results['knn_training '+ str(x)] = knn.score(X_train, y_train)\n",
    "    train_time = dt.datetime.now()\n",
    "    print('train score logged', train_time - start_time)\n",
    "    results['knn_test '+ str(x)] = knn.score(X_test, y_test)\n",
    "    print('test score logged', dt.datetime.now() - train_time)\n",
    "\n",
    "print('knn done ', dt.datetime.now() - svc_time)\n",
    "\n",
    "for x in [20, 50, 70, 100]:\n",
    "    print('Tree count =', x, '     running...')\n",
    "    for y in [50, 100, 200, 300]:\n",
    "        forest = RandomForestClassifier(n_estimators = x, max_depth = y).fit(X_train, y_train)\n",
    "        results['forest_training trees:'+ str(x) + ' dpth: '+str(y)] = forest.score(X_train, y_train)\n",
    "        results['forest_test trees:'+ str(x) + ' dpth: '+str(y)] = forest.score(X_test, y_test)\n",
    "        \n",
    "for y in [50, 100, 200, 300]:\n",
    "    dtree = DecisionTreeClassifier(max_depth = y).fit(X_train, y_train)\n",
    "    results['dtree_training ' + ' dpth: '+str(y)] = dtree.score(X_train, y_train)\n",
    "    results['dtree_test ' + ' dpth: '+str(y)] = dtree.score(X_test, y_test)\n",
    "\n",
    "print('\\nALL DONE! - Total time spent training/testing (hh:mm:ss):', dt.datetime.now() - begin_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 23796 features per sample; expecting 16384",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-5350649da261>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mridge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRidgeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mresults_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ridge '\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mridge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mridge_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    498\u001b[0m         \"\"\"\n\u001b[0;32m    499\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \"\"\"\n\u001b[1;32m--> 309\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[0;32m    289\u001b[0m                              % (X.shape[1], n_features))\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 23796 features per sample; expecting 16384"
     ]
    }
   ],
   "source": [
    "begin_time = dt.datetime.now()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(titles_vectorized_bow, target, test_size = 0.2, random_state = 2021)\n",
    "\n",
    "XX_test = vectorize_dataframe(gaming_df)\n",
    "yy_test = gaming_df.score_class\n",
    "\n",
    "results_x = {'Model':'Score'}\n",
    "for x in [0.01, 0.1, 1, 5, 10, 20]:\n",
    "    ridge = RidgeClassifier(alpha = x, max_iter=5000).fit(X_train, y_train)\n",
    "    results_x['ridge '+ str(x)] = ridge.score(XX_test, yy_test)\n",
    "    \n",
    "ridge_time = dt.datetime.now()\n",
    "print('ridge done ', ridge_time - begin_time)\n",
    "\n",
    "# SVC_model = SVC().fit(X_train, y_train)\n",
    "# results['svc_training'] = SVC_model.score(X_train, y_train)\n",
    "# results['svc_test'] = SVC_model.score(X_test, y_test)\n",
    "\n",
    "svc_time = dt.datetime.now()\n",
    "# print('svc done ', svc_time - ridge_time)\n",
    "\n",
    "for x in range(1, 8):\n",
    "    print('Neighbors:', x)\n",
    "    start_time = dt.datetime.now()\n",
    "    knn = KNeighborsClassifier(n_neighbors = x, n_jobs=-1).fit(X_train, y_train)\n",
    "    results_x['knn '+ str(x)] = knn.score(XX_test, yy_test)\n",
    "    train_time = dt.datetime.now()\n",
    "    print('score logged', train_time - start_time)\n",
    "\n",
    "print('knn done ', dt.datetime.now() - svc_time)\n",
    "\n",
    "for x in [20, 50, 70, 100]:\n",
    "    print('Tree count =', x, '     running...')\n",
    "    for y in [50, 100, 200, 300]:\n",
    "        forest = RandomForestClassifier(n_estimators = x, max_depth = y).fit(X_train, y_train)\n",
    "        results_x['forest | trees:'+ str(x) + ', dpth: '+str(y)] = forest.score(XX_test, yy_test)\n",
    "        \n",
    "for y in [50, 100, 200, 300]:\n",
    "    dtree = DecisionTreeClassifier(max_depth = y).fit(X_train, y_train)\n",
    "    results_x['dtree |' + ' dpth: '+str(y)] = dtree.score(X_train, yy_test)\n",
    "print('\\nALL DONE! - Total time spent training/testing (hh:mm:ss):', dt.datetime.now() - begin_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score\n",
      "ridge_training 0.01 0.9928714000570288\n",
      "ridge_test 0.01 0.6670467502850627\n",
      "ridge_training 0.1 0.9923011120615911\n",
      "ridge_test 0.1 0.7023945267958951\n",
      "ridge_training 1 0.9887368120901056\n",
      "ridge_test 1 0.7331812998859749\n",
      "ridge_training 5 0.9518106643855146\n",
      "ridge_test 5 0.7542759407069556\n",
      "ridge_training 10 0.9252922725976618\n",
      "ridge_test 10 0.7588369441277081\n",
      "ridge_training 20 0.8956372968349017\n",
      "ridge_test 20 0.7679589509692132\n",
      "knn_training 1 0.9985742800114058\n",
      "knn_test 1 0.6864310148232611\n",
      "knn_training 2 0.8448816652409467\n",
      "knn_test 2 0.7565564424173318\n",
      "knn_training 3 0.831194753350442\n",
      "knn_test 3 0.758266818700114\n",
      "knn_training 4 0.8197889934416881\n",
      "knn_test 4 0.7668187001140251\n",
      "knn_training 5 0.8136583974907328\n",
      "knn_test 5 0.7753705815279361\n",
      "knn_training 6 0.8095238095238095\n",
      "knn_test 6 0.7805017103762828\n",
      "knn_training 7 0.8058169375534645\n",
      "knn_test 7 0.7770809578107184\n",
      "forest_training trees:20 dpth: 50 0.8093812375249501\n",
      "forest_test trees:20 dpth: 50 0.7890535917901939\n",
      "forest_training trees:20 dpth: 100 0.8674080410607357\n",
      "forest_test trees:20 dpth: 100 0.7873432155074116\n",
      "forest_training trees:20 dpth: 200 0.9459652124322783\n",
      "forest_test trees:20 dpth: 200 0.7827822120866591\n",
      "forest_training trees:20 dpth: 300 0.9897348160821214\n",
      "forest_test trees:20 dpth: 300 0.7816419612314709\n",
      "forest_training trees:50 dpth: 50 0.8063872255489022\n",
      "forest_test trees:50 dpth: 50 0.7896237172177879\n",
      "forest_training trees:50 dpth: 100 0.8618477331052181\n",
      "forest_test trees:50 dpth: 100 0.7879133409350056\n",
      "forest_training trees:50 dpth: 200 0.955945252352438\n",
      "forest_test trees:50 dpth: 200 0.7844925883694412\n",
      "forest_training trees:50 dpth: 300 0.9942971200456231\n",
      "forest_test trees:50 dpth: 300 0.7810718358038768\n",
      "forest_training trees:70 dpth: 50 0.8071000855431993\n",
      "forest_test trees:70 dpth: 50 0.7890535917901939\n",
      "forest_training trees:70 dpth: 100 0.8694040490447676\n",
      "forest_test trees:70 dpth: 100 0.7862029646522235\n",
      "forest_training trees:70 dpth: 200 0.9632164242942686\n",
      "forest_test trees:70 dpth: 200 0.7833523375142531\n",
      "forest_training trees:70 dpth: 300 0.9947248360422013\n",
      "forest_test trees:70 dpth: 300 0.7810718358038768\n",
      "forest_training trees:100 dpth: 50 0.8048189335614485\n",
      "forest_test trees:100 dpth: 50 0.7896237172177879\n",
      "forest_training trees:100 dpth: 100 0.8686911890504705\n",
      "forest_test trees:100 dpth: 100 0.7879133409350056\n",
      "forest_training trees:100 dpth: 200 0.9617907043056744\n",
      "forest_test trees:100 dpth: 200 0.7839224629418472\n",
      "forest_training trees:100 dpth: 300 0.9970059880239521\n",
      "forest_test trees:100 dpth: 300 0.7810718358038768\n",
      "dtree_training  dpth: 50 0.9180211006558312\n",
      "dtree_test  dpth: 50 0.7480045610034207\n",
      "dtree_training  dpth: 100 0.9600798403193613\n",
      "dtree_test  dpth: 100 0.7309007981755986\n",
      "dtree_training  dpth: 200 0.9885942400912461\n",
      "dtree_test  dpth: 200 0.7206385404789054\n",
      "dtree_training  dpth: 300 0.9985742800114058\n",
      "dtree_test  dpth: 300 0.7166476624857469\n"
     ]
    }
   ],
   "source": [
    "for k, v in results.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(\"datasets\\\\\\model_results\\\\unigram_science.csv\", \"w\")\n",
    "\n",
    "writer = csv.writer(a_file)\n",
    "for k, v in results.items():\n",
    "    writer.writerow([k, v])\n",
    "\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ridge_training 0.01</td>\n",
       "      <td>0.993157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ridge_test 0.01</td>\n",
       "      <td>0.669327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ridge_training 0.1</td>\n",
       "      <td>0.992444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ridge_test 0.1</td>\n",
       "      <td>0.702965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ridge_training 1</td>\n",
       "      <td>0.988879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ridge_test 1</td>\n",
       "      <td>0.733751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ridge_training 5</td>\n",
       "      <td>0.951668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ridge_test 5</td>\n",
       "      <td>0.754276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ridge_training 10</td>\n",
       "      <td>0.925150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ridge_test 10</td>\n",
       "      <td>0.759407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ridge_training 20</td>\n",
       "      <td>0.896208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ridge_test 20</td>\n",
       "      <td>0.767959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svc_training</td>\n",
       "      <td>0.802395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>svc_test</td>\n",
       "      <td>0.789624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>knn_training 1</td>\n",
       "      <td>0.998574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>knn_test 1</td>\n",
       "      <td>0.683010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>knn_training 2</td>\n",
       "      <td>0.845452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>knn_test 2</td>\n",
       "      <td>0.755416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>knn_training 3</td>\n",
       "      <td>0.832335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>knn_test 3</td>\n",
       "      <td>0.758837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>knn_training 4</td>\n",
       "      <td>0.819504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>knn_test 4</td>\n",
       "      <td>0.761688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>knn_training 5</td>\n",
       "      <td>0.812660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>knn_test 5</td>\n",
       "      <td>0.777081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>forest_traininge trees:20 dpth: 50</td>\n",
       "      <td>0.809952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>forest_test trees:20 dpth: 50</td>\n",
       "      <td>0.789624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>dtree_training  dpth: 50</td>\n",
       "      <td>0.917879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>dtree_test  dpth: 50</td>\n",
       "      <td>0.748005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>forest_traininge trees:20 dpth: 100</td>\n",
       "      <td>0.867551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>forest_test trees:20 dpth: 100</td>\n",
       "      <td>0.786203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Model     Score\n",
       "0                   ridge_training 0.01  0.993157\n",
       "1                       ridge_test 0.01  0.669327\n",
       "2                    ridge_training 0.1  0.992444\n",
       "3                        ridge_test 0.1  0.702965\n",
       "4                      ridge_training 1  0.988879\n",
       "5                          ridge_test 1  0.733751\n",
       "6                      ridge_training 5  0.951668\n",
       "7                          ridge_test 5  0.754276\n",
       "8                     ridge_training 10  0.925150\n",
       "9                         ridge_test 10  0.759407\n",
       "10                    ridge_training 20  0.896208\n",
       "11                        ridge_test 20  0.767959\n",
       "12                         svc_training  0.802395\n",
       "13                             svc_test  0.789624\n",
       "14                       knn_training 1  0.998574\n",
       "15                           knn_test 1  0.683010\n",
       "16                       knn_training 2  0.845452\n",
       "17                           knn_test 2  0.755416\n",
       "18                       knn_training 3  0.832335\n",
       "19                           knn_test 3  0.758837\n",
       "20                       knn_training 4  0.819504\n",
       "21                           knn_test 4  0.761688\n",
       "22                       knn_training 5  0.812660\n",
       "23                           knn_test 5  0.777081\n",
       "24   forest_traininge trees:20 dpth: 50  0.809952\n",
       "25        forest_test trees:20 dpth: 50  0.789624\n",
       "26             dtree_training  dpth: 50  0.917879\n",
       "27                 dtree_test  dpth: 50  0.748005\n",
       "28  forest_traininge trees:20 dpth: 100  0.867551\n",
       "29       forest_test trees:20 dpth: 100  0.786203"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df2 = pd.read_csv('datasets\\\\model_results\\\\unigram_wsb.csv')\n",
    "\n",
    "result_df2.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "could not allocate 41877504 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-3ebe3bc77ebf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbegin_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mforest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    167\u001b[0m                                                         indices=indices)\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    896\u001b[0m         \"\"\"\n\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.Tree._add_node\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.Tree._resize_c\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_utils.pyx\u001b[0m in \u001b[0;36msklearn.tree._utils.safe_realloc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: could not allocate 41877504 bytes"
     ]
    }
   ],
   "source": [
    "begin_time = dt.datetime.now()\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 100).fit(X_train, y_train)\n",
    "test_model(forest)\n",
    "\n",
    "train_end_time = dt.datetime.now()\n",
    "print('Time spent training (hh:mm:ss):',  train_end_time - begin_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('aaai', 0.43624606175774516)\n",
      "('visualization', 0.3223039299815076)\n",
      "('agedependent', 0.3194857417795549)\n",
      "('ampamp', 0.2989954111354649)\n",
      "('aggravates', 0.29860082349455064)\n",
      "('neuropathic', 0.2947864426034513)\n",
      "('painfree', 0.28919528208244805)\n",
      "('genebased', 0.2883023619813986)\n",
      "('urbanization', 0.2733032167796802)\n",
      "('movement', 0.27223045102284404)\n",
      "\n",
      "\n",
      "('finelycrushed', -0.4696689965724894)\n",
      "('viii', -0.43792346714062)\n",
      "('yeast', -0.3933578605576364)\n",
      "('ancienttimes', -0.38286713799763833)\n",
      "('tetrahydrocannabinol', -0.37844303043497324)\n",
      "('autismrelated', -0.3699753451279366)\n",
      "('heights', -0.35714510334625044)\n",
      "('mitigates', -0.3540053596705342)\n",
      "('halffemale', -0.34956851962079716)\n",
      "('thousand', -0.33847137317057907)\n",
      "('posttime', -0.053531051994896224)\n",
      "('title_length', 0.009213906232209745)\n"
     ]
    }
   ],
   "source": [
    "feature_names_total = vectorizer.get_feature_names()\n",
    "feature_names_total.extend(['posttime', 'title_length'])\n",
    "sorted_coefs_desc = sorted(list(zip(list(feature_names_total), logreg.coef_[0])), key = lambda e: e[1], reverse=True)\n",
    "sorted_coefs_asc = sorted(list(zip(list(feature_names_total), logreg.coef_[0])), key = lambda e: e[1])\n",
    "features_forest = sorted(list(zip(list(feature_names_total), forest.feature_importances_)), key = lambda e: e[1], reverse=True)\n",
    "# print(features_forest[:10], '\\n')\n",
    "\n",
    "for x in range(10):\n",
    "    print(sorted_coefs_desc[x])\n",
    "\n",
    "print('\\n')\n",
    "for x in range(10):\n",
    "    \n",
    "    print(sorted_coefs_asc[x])\n",
    "for x in range(len(sorted_coefs_desc)):\n",
    "    if sorted_coefs_desc[x][0] == 'posttime' :\n",
    "        print(sorted_coefs_desc[x])\n",
    "    else:\n",
    "        pass\n",
    "for x in range(len(sorted_coefs_desc)):\n",
    "    if sorted_coefs_desc[x][0] == 'title_length' :\n",
    "        print(sorted_coefs_desc[x])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7024, 15)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
