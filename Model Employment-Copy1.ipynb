{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import datetime as dt\n",
    "from scipy import sparse\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, LinearRegression, LogisticRegression, RidgeClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Loading dataset + defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_df = pd.read_csv('datasets\\\\science_dataset_updated.csv',) #Loads dataset\n",
    "\n",
    "stop_words = set(stopwords.words('english')) #Defines stopwords\n",
    "ps = PorterStemmer() #Defines stemmer\n",
    "\n",
    "def preprocess_text_col(dataframe, column_name): #Function for preprocessing text data for model-use by adding 'title-cleaned' column to given dataframe\n",
    "    \n",
    "    def remove_punctuation(text): #Removes punctuation from string e.g. 'This is a string. This is another string' → 'this is a string This is another string' \n",
    "        no_punct=[words.lower() for words in text if words not in string.punctuation and words.isdigit() == False]\n",
    "        words_wo_punct=''.join(no_punct)\n",
    "        return words_wo_punct\n",
    "    def tokenize(text): #Tokenizes string e.g. 'This is a string' → ['this', 'is', 'a', 'string']\n",
    "        split=re.split(\"\\W+\", text) \n",
    "        return split\n",
    "    def remove_stopwords(text): #Removes stopwords list of strings e.g. ['this', 'is', 'a', 'string'] → ['string']\n",
    "        text=[word for word in text if word not in stop_words]\n",
    "        return text\n",
    "    def stem_nested_list(lst): #Stems words in a nested list and returns a nested list with stemmed words\n",
    "        master_list = []\n",
    "        for x in lst:\n",
    "            stemmed_list = [ps.stem(word) for word in x]\n",
    "            master_list.append(stemmed_list)\n",
    "        return master_list\n",
    "    \n",
    "    title_wo_punct = [remove_punctuation(x) for x in dataframe[column_name]]\n",
    "    title_wo_punct_split = [tokenize(word) for word in title_wo_punct]\n",
    "    title_wo_punct_split_stopwords = [remove_stopwords(word) for word in title_wo_punct_split]\n",
    "    dataframe['title_cleaned'] = title_wo_punct_split_stopwords\n",
    "#     dataframe['title_cleaned'] = stem_nested_list(title_wo_punct_split_stopwords)    \n",
    "\n",
    "def create_features(dataframe):\n",
    "    dataframe['timestamp'] = pd.to_datetime(dataframe['timestamp']) #Changing 'timestamp' column to dtype = datetime\n",
    "    dataframe['24h_posttime'] = dataframe['timestamp'].dt.hour #Adding hour posttime to dataset\n",
    "    \n",
    "    dataframe['score_class'] = \"\" #Creating the score_class column in the dataframe and filling it with empty strings\n",
    "    \n",
    "    dataframe['body'] = dataframe['body'].astype(str)\n",
    "    dataframe.loc[(science_df['body'] == 'nan') | (dataframe['body'] == '[deleted]'), 'has_body_text'] = int(0) \n",
    "    dataframe.loc[(science_df['body'] != 'nan') & (dataframe['body'] != '[deleted]'), 'has_body_text'] = int(1)\n",
    "    dataframe['has_body_text'] = dataframe['has_body_text'].astype(int)\n",
    "    \n",
    "    for x in range(len(dataframe)): #Generates classes for score percentiles\n",
    "        if dataframe['score'][x] >= dataframe.score.quantile(0.99):\n",
    "            dataframe['score_class'][x] = 'Top 1%'\n",
    "        elif dataframe['score'][x] >= dataframe.score.quantile(0.95):\n",
    "            dataframe['score_class'][x] = 'Top 5%'\n",
    "        elif dataframe['score'][x] >= dataframe.score.quantile(0.9):\n",
    "            dataframe['score_class'][x] = 'Top 10%'\n",
    "        elif dataframe['score'][x] >= dataframe.score.quantile(0.8):\n",
    "            dataframe['score_class'][x] = 'Top 20%'\n",
    "        else:\n",
    "            dataframe['score_class'][x] = 'Last 80%'\n",
    "    \n",
    "def test_model(model): #Function for testing model(s)\n",
    "    if type(model) == list:\n",
    "        for x in range(len(model)):\n",
    "            print(\"Training score for {}: {:.3f}\".format(str(model[x]), model[x].score(X_train, y_train)))\n",
    "            print(\"Test score for {}: {:.2f}\\n\".format(str(model[x]), model[x].score(X_test, y_test)))\n",
    "    else:\n",
    "        print(\"Training score for {}: {:.3f}\".format(str(model), model.score(X_train, y_train)))\n",
    "        print(\"Test score for {}: {:.2f}\".format(str(model), model.score(X_test, y_test)))\n",
    "        \n",
    "def col_to_matrix(dataframe, column): #Function for converting a column from a pd.dataframe into a scipy.sparse.csr_matrix\n",
    "    matrix = dataframe[column].values[np.newaxis] #Creating 2D np array from column by adding an axis to original 1D array (df[col].values)\n",
    "    matrix = matrix.T #Transposing (rotating) array e.g. (1, 823) to (823, 1)\n",
    "    matrix = sparse.csr_matrix(matrix) #Creating matrix from array\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Preprocessing text-data for model-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-2a4dda0e9403>:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['score_class'][x] = 'Last 80%'\n",
      "<ipython-input-2-2a4dda0e9403>:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['score_class'][x] = 'Top 1%'\n",
      "<ipython-input-2-2a4dda0e9403>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['score_class'][x] = 'Top 20%'\n",
      "<ipython-input-2-2a4dda0e9403>:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['score_class'][x] = 'Top 10%'\n",
      "<ipython-input-2-2a4dda0e9403>:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['score_class'][x] = 'Top 5%'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['post_ID', 'title', 'url', 'author', 'timestamp', 'comms_num',\n",
       "       'permalink', 'body', 'Flair', 'title length', '24h_posttime', 'score',\n",
       "       'score_class', 'has_body_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_features(science_df)\n",
    "science_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent (hh:mm:ss): 0:00:00.579284\n"
     ]
    }
   ],
   "source": [
    "begin_time = dt.datetime.now()\n",
    "\n",
    "preprocess_text_col(science_df, 'title')\n",
    "score_list = sorted([x for x in science_df.score]) #Generates a list of all scores sorted in ascending order\n",
    "\n",
    "post_time = col_to_matrix(science_df, '24h_posttime')\n",
    "title_len = col_to_matrix(science_df, 'title length')\n",
    "has_body_text = col_to_matrix(science_df, 'has_body_text')\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=False, analyzer=lambda x: x)\n",
    "titles_vectorized = vectorizer.fit_transform(science_df.title_cleaned)\n",
    "titles_vectorized = sparse.hstack((post_time, titles_vectorized)) #Adding posttime column to matrix\n",
    "titles_vectorized = sparse.hstack((title_len, titles_vectorized)) #Adding title_length column to matrix\n",
    "titles_vectorized = sparse.hstack((has_body_text, titles_vectorized)) #Adding has_body_text column to matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(titles_vectorized, science_df.score_class, test_size = 0.2, random_state = 2021)\n",
    "\n",
    "print('Time spent (hh:mm:ss):', dt.datetime.now() - begin_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Creating, training and testing models (X_train2 = regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score for RidgeClassifier(alpha=0.01, max_iter=5000): 0.993\n",
      "Test score for RidgeClassifier(alpha=0.01, max_iter=5000): 0.67\n",
      "Training score for RidgeClassifier(alpha=0.1, max_iter=5000): 0.992\n",
      "Test score for RidgeClassifier(alpha=0.1, max_iter=5000): 0.70\n",
      "Training score for RidgeClassifier(alpha=1, max_iter=5000): 0.989\n",
      "Test score for RidgeClassifier(alpha=1, max_iter=5000): 0.73\n",
      "Training score for SVC(C=1): 0.802\n",
      "Test score for SVC(C=1): 0.79\n",
      "Training score for SVC(C=3): 0.802\n",
      "Test score for SVC(C=3): 0.79\n",
      "Training score for SVC(C=5): 0.802\n",
      "Test score for SVC(C=5): 0.79\n",
      "Training score for KNeighborsClassifier(n_neighbors=1): 0.999\n",
      "Test score for KNeighborsClassifier(n_neighbors=1): 0.68\n",
      "Training score for KNeighborsClassifier(n_neighbors=2): 0.845\n",
      "Test score for KNeighborsClassifier(n_neighbors=2): 0.76\n",
      "Training score for KNeighborsClassifier(n_neighbors=3): 0.832\n",
      "Test score for KNeighborsClassifier(n_neighbors=3): 0.76\n",
      "Training score for KNeighborsClassifier(n_neighbors=4): 0.820\n",
      "Test score for KNeighborsClassifier(n_neighbors=4): 0.76\n",
      "Training score for KNeighborsClassifier(): 0.813\n",
      "Test score for KNeighborsClassifier(): 0.78\n",
      "Training score for RandomForestClassifier(max_depth=50, n_estimators=20): 0.811\n",
      "Test score for RandomForestClassifier(max_depth=50, n_estimators=20): 0.79\n",
      "\n",
      "Training score for DecisionTreeClassifier(max_depth=50): 0.918\n",
      "Test score for DecisionTreeClassifier(max_depth=50): 0.74\n",
      "\n",
      "Training score for RandomForestClassifier(max_depth=100, n_estimators=20): 0.863\n",
      "Test score for RandomForestClassifier(max_depth=100, n_estimators=20): 0.79\n",
      "\n",
      "Training score for DecisionTreeClassifier(max_depth=100): 0.963\n",
      "Test score for DecisionTreeClassifier(max_depth=100): 0.73\n",
      "\n",
      "Training score for RandomForestClassifier(max_depth=200, n_estimators=20): 0.948\n",
      "Test score for RandomForestClassifier(max_depth=200, n_estimators=20): 0.78\n",
      "\n",
      "Training score for DecisionTreeClassifier(max_depth=200): 0.988\n",
      "Test score for DecisionTreeClassifier(max_depth=200): 0.72\n",
      "\n",
      "Training score for RandomForestClassifier(max_depth=300, n_estimators=20): 0.986\n",
      "Test score for RandomForestClassifier(max_depth=300, n_estimators=20): 0.78\n",
      "\n",
      "Training score for DecisionTreeClassifier(max_depth=300): 0.999\n",
      "Test score for DecisionTreeClassifier(max_depth=300): 0.71\n",
      "\n",
      "Training score for RandomForestClassifier(max_depth=50, n_estimators=50): 0.805\n",
      "Test score for RandomForestClassifier(max_depth=50, n_estimators=50): 0.79\n",
      "\n",
      "Training score for DecisionTreeClassifier(max_depth=50): 0.918\n",
      "Test score for DecisionTreeClassifier(max_depth=50): 0.75\n",
      "\n",
      "Training score for RandomForestClassifier(max_depth=100, n_estimators=50): 0.859\n",
      "Test score for RandomForestClassifier(max_depth=100, n_estimators=50): 0.79\n",
      "\n",
      "Training score for DecisionTreeClassifier(max_depth=100): 0.959\n",
      "Test score for DecisionTreeClassifier(max_depth=100): 0.74\n",
      "\n",
      "Training score for RandomForestClassifier(max_depth=200, n_estimators=50): 0.965\n",
      "Test score for RandomForestClassifier(max_depth=200, n_estimators=50): 0.78\n",
      "\n",
      "Training score for DecisionTreeClassifier(max_depth=200): 0.988\n",
      "Test score for DecisionTreeClassifier(max_depth=200): 0.72\n",
      "\n",
      "Training score for RandomForestClassifier(max_depth=300, n_estimators=50): 0.993\n",
      "Test score for RandomForestClassifier(max_depth=300, n_estimators=50): 0.78\n",
      "\n",
      "Training score for DecisionTreeClassifier(max_depth=300): 0.999\n",
      "Test score for DecisionTreeClassifier(max_depth=300): 0.72\n",
      "\n",
      "Training score for RandomForestClassifier(max_depth=50, n_estimators=70): 0.808\n",
      "Test score for RandomForestClassifier(max_depth=50, n_estimators=70): 0.79\n",
      "\n",
      "Training score for DecisionTreeClassifier(max_depth=50): 0.918\n",
      "Test score for DecisionTreeClassifier(max_depth=50): 0.75\n",
      "\n",
      "Training score for RandomForestClassifier(max_depth=100, n_estimators=70): 0.866\n",
      "Test score for RandomForestClassifier(max_depth=100, n_estimators=70): 0.79\n",
      "\n",
      "Training score for DecisionTreeClassifier(max_depth=100): 0.965\n",
      "Test score for DecisionTreeClassifier(max_depth=100): 0.73\n",
      "\n",
      "Training score for RandomForestClassifier(max_depth=200, n_estimators=70): 0.955\n",
      "Test score for RandomForestClassifier(max_depth=200, n_estimators=70): 0.78\n",
      "\n",
      "Training score for DecisionTreeClassifier(max_depth=200): 0.988\n",
      "Test score for DecisionTreeClassifier(max_depth=200): 0.72\n",
      "\n",
      "Training score for RandomForestClassifier(max_depth=300, n_estimators=70): 0.997\n",
      "Test score for RandomForestClassifier(max_depth=300, n_estimators=70): 0.78\n",
      "\n",
      "Training score for DecisionTreeClassifier(max_depth=300): 0.999\n",
      "Test score for DecisionTreeClassifier(max_depth=300): 0.71\n",
      "\n",
      "Training score for RandomForestClassifier(max_depth=50): 0.805\n",
      "Test score for RandomForestClassifier(max_depth=50): 0.79\n",
      "\n",
      "Training score for DecisionTreeClassifier(max_depth=50): 0.919\n",
      "Test score for DecisionTreeClassifier(max_depth=50): 0.75\n",
      "\n",
      "Training score for RandomForestClassifier(max_depth=100): 0.868\n",
      "Test score for RandomForestClassifier(max_depth=100): 0.79\n",
      "\n",
      "Training score for DecisionTreeClassifier(max_depth=100): 0.964\n",
      "Test score for DecisionTreeClassifier(max_depth=100): 0.73\n",
      "\n",
      "Training score for RandomForestClassifier(max_depth=200): 0.963\n",
      "Test score for RandomForestClassifier(max_depth=200): 0.78\n",
      "\n",
      "Training score for DecisionTreeClassifier(max_depth=200): 0.985\n",
      "Test score for DecisionTreeClassifier(max_depth=200): 0.73\n",
      "\n",
      "Training score for RandomForestClassifier(max_depth=300): 0.997\n",
      "Test score for RandomForestClassifier(max_depth=300): 0.78\n",
      "\n",
      "Training score for DecisionTreeClassifier(max_depth=300): 0.999\n",
      "Test score for DecisionTreeClassifier(max_depth=300): 0.72\n",
      "\n",
      "Time spent training (hh:mm:ss): 0:03:22.874138\n"
     ]
    }
   ],
   "source": [
    "begin_time = dt.datetime.now()\n",
    "\n",
    "for x in [0.01, 0.1, 1]:\n",
    "    ridge = RidgeClassifier(alpha = x, max_iter=5000).fit(X_train, y_train)\n",
    "    SVC_model = SVC(C = x).fit(X_train, y_train)\n",
    "    test_model(ridge)\n",
    "\n",
    "for x in [1, 3, 5]:\n",
    "    SVC_model = SVC(C = x).fit(X_train, y_train)\n",
    "    test_model(SVC_model)\n",
    "    \n",
    "for x in [1, 2, 3, 4, 5]:\n",
    "    knn = KNeighborsClassifier(n_neighbors = x).fit(X_train, y_train)\n",
    "    test_model(knn)\n",
    "    \n",
    "for x in [20, 50, 70, 100]:\n",
    "    for y in [50, 100, 200, 300]:\n",
    "        forest = RandomForestClassifier(n_estimators = x, max_depth = y).fit(X_train, y_train)\n",
    "        dtree = DecisionTreeClassifier(max_depth = y).fit(X_train, y_train)\n",
    "        test_model([forest, dtree])\n",
    "        \n",
    "train_end_time = dt.datetime.now()\n",
    "print('Time spent training (hh:mm:ss):', train_end_time - begin_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "could not allocate 41877504 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-3ebe3bc77ebf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbegin_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mforest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    167\u001b[0m                                                         indices=indices)\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    896\u001b[0m         \"\"\"\n\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\BDA\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.Tree._add_node\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.Tree._resize_c\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_utils.pyx\u001b[0m in \u001b[0;36msklearn.tree._utils.safe_realloc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: could not allocate 41877504 bytes"
     ]
    }
   ],
   "source": [
    "begin_time = dt.datetime.now()\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 100).fit(X_train, y_train)\n",
    "test_model(forest)\n",
    "\n",
    "train_end_time = dt.datetime.now()\n",
    "print('Time spent training (hh:mm:ss):',  train_end_time - begin_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('aaai', 0.43624606175774516)\n",
      "('visualization', 0.3223039299815076)\n",
      "('agedependent', 0.3194857417795549)\n",
      "('ampamp', 0.2989954111354649)\n",
      "('aggravates', 0.29860082349455064)\n",
      "('neuropathic', 0.2947864426034513)\n",
      "('painfree', 0.28919528208244805)\n",
      "('genebased', 0.2883023619813986)\n",
      "('urbanization', 0.2733032167796802)\n",
      "('movement', 0.27223045102284404)\n",
      "\n",
      "\n",
      "('finelycrushed', -0.4696689965724894)\n",
      "('viii', -0.43792346714062)\n",
      "('yeast', -0.3933578605576364)\n",
      "('ancienttimes', -0.38286713799763833)\n",
      "('tetrahydrocannabinol', -0.37844303043497324)\n",
      "('autismrelated', -0.3699753451279366)\n",
      "('heights', -0.35714510334625044)\n",
      "('mitigates', -0.3540053596705342)\n",
      "('halffemale', -0.34956851962079716)\n",
      "('thousand', -0.33847137317057907)\n",
      "('posttime', -0.053531051994896224)\n",
      "('title_length', 0.009213906232209745)\n"
     ]
    }
   ],
   "source": [
    "feature_names_total = vectorizer.get_feature_names()\n",
    "feature_names_total.extend(['posttime', 'title_length'])\n",
    "sorted_coefs_desc = sorted(list(zip(list(feature_names_total), logreg.coef_[0])), key = lambda e: e[1], reverse=True)\n",
    "sorted_coefs_asc = sorted(list(zip(list(feature_names_total), logreg.coef_[0])), key = lambda e: e[1])\n",
    "features_forest = sorted(list(zip(list(feature_names_total), forest.feature_importances_)), key = lambda e: e[1], reverse=True)\n",
    "# print(features_forest[:10], '\\n')\n",
    "\n",
    "for x in range(10):\n",
    "    print(sorted_coefs_desc[x])\n",
    "\n",
    "print('\\n')\n",
    "for x in range(10):\n",
    "    \n",
    "    print(sorted_coefs_asc[x])\n",
    "for x in range(len(sorted_coefs_desc)):\n",
    "    if sorted_coefs_desc[x][0] == 'posttime' :\n",
    "        print(sorted_coefs_desc[x])\n",
    "    else:\n",
    "        pass\n",
    "for x in range(len(sorted_coefs_desc)):\n",
    "    if sorted_coefs_desc[x][0] == 'title_length' :\n",
    "        print(sorted_coefs_desc[x])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_df['24h_posttime'].value_counts()\n",
    "science_df['body'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
